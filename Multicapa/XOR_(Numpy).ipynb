{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAB1nTjsDj1xqPvVwozu8W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karvs1458-gif/Inteligencia-Artificial/blob/main/Multicapa/XOR_(Numpy).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UbQjqt1PWS_d"
      },
      "outputs": [],
      "source": [
        "#esta linea de codigo es para importar los modulos necesarios\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#determinamos los datos de entrenamiento:\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]) #datos de entrada\n",
        "y = np.array([[0], [1], [1], [0]]) #datos de salida"
      ],
      "metadata": {
        "id": "Yb2GXShaW-1X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#determinamos la arquitectura de nuestra red:\n",
        "np.random.seed(1)\n",
        "input_neurons = 2   #entrada de la red de 2 neuronas\n",
        "hidden_neurons = 4  #capa oculta de 4 neuronas\n",
        "output_neurons = 1  #solo una neurona en nuestra capa de salida"
      ],
      "metadata": {
        "id": "40ZeMTzgXCZ-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inicialización de los pesos y sesgos\n",
        "weights_input_hidden = np.random.uniform(size=(input_neurons, hidden_neurons))  #crea una matriz de pesos entre la capa de entrada y la capa oculta\n",
        "bias_hidden = np.random.uniform(size=(1, hidden_neurons)) #crea el vector de sesgos para la capa oculta\n",
        "weights_hidden_output = np.random.uniform(size=(hidden_neurons, output_neurons))  #crea los pesos que conectan la capa oculta con la de salida\n",
        "bias_output = np.random.uniform(size=(1, output_neurons)) #crea el bias para la capa de salida\n",
        "#el bias ayuda a que una neurona se active incluso cuando todas las entradas son cero y le da más flexibilidad al modelo para aprender."
      ],
      "metadata": {
        "id": "KYzDA0CKXIXy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de activación sigmoide\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivada de la función sigmoide\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)"
      ],
      "metadata": {
        "id": "6Rsd3GP1XMgl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparámetros\n",
        "learning_rate = 0.1\n",
        "epochs = 10000"
      ],
      "metadata": {
        "id": "YkXkis6YXNtX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento de la red neuronal\n",
        "for epoch in range(epochs):\n",
        "    # Paso hacia adelante (Forward pass)\n",
        "    input_layer = X\n",
        "    hidden_layer_input = np.dot(input_layer, weights_input_hidden) + bias_hidden\n",
        "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
        "    output = sigmoid(output_layer_input)\n",
        "\n",
        "    # Cálculo del error\n",
        "    error = y - output\n",
        "    mse = np.mean((error) ** 2)\n",
        "    # Mostrar el progreso\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        _mse = \"{:.20f}\".format(mse)\n",
        "        print(f'Época {epoch + 1}, Loss function (MSE): {_mse}')\n",
        "\n",
        "    # Retropropagación (Backpropagation)\n",
        "    d_output = error * sigmoid_derivative(output)\n",
        "    error_hidden = d_output.dot(weights_hidden_output.T)\n",
        "    d_hidden = error_hidden * sigmoid_derivative(hidden_layer_output)\n",
        "\n",
        "    # Actualización de pesos y sesgos\n",
        "    weights_hidden_output += hidden_layer_output.T.dot(d_output) * learning_rate\n",
        "    bias_output += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
        "    weights_input_hidden += input_layer.T.dot(d_hidden) * learning_rate\n",
        "    bias_hidden += np.sum(d_hidden, axis=0, keepdims=True) * learning_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1aLJ_QQXQ8s",
        "outputId": "97b962c1-e342-41a4-d231-930b7c434495"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 100, Loss function (MSE): 0.24983287726390090988\n",
            "Época 200, Loss function (MSE): 0.24976158002835310845\n",
            "Época 300, Loss function (MSE): 0.24968632610837576680\n",
            "Época 400, Loss function (MSE): 0.24960487845253204187\n",
            "Época 500, Loss function (MSE): 0.24951497482937587402\n",
            "Época 600, Loss function (MSE): 0.24941395623417036975\n",
            "Época 700, Loss function (MSE): 0.24929861946155457142\n",
            "Época 800, Loss function (MSE): 0.24916503506240891830\n",
            "Época 900, Loss function (MSE): 0.24900831998348221807\n",
            "Época 1000, Loss function (MSE): 0.24882235334153751660\n",
            "Época 1100, Loss function (MSE): 0.24859942378797927898\n",
            "Época 1200, Loss function (MSE): 0.24832979852365411055\n",
            "Época 1300, Loss function (MSE): 0.24800120790643448432\n",
            "Época 1400, Loss function (MSE): 0.24759824578584252452\n",
            "Época 1500, Loss function (MSE): 0.24710169260774333955\n",
            "Época 1600, Loss function (MSE): 0.24648777186249803961\n",
            "Época 1700, Loss function (MSE): 0.24572734481284236319\n",
            "Época 1800, Loss function (MSE): 0.24478503162895287604\n",
            "Época 1900, Loss function (MSE): 0.24361823380468561329\n",
            "Época 2000, Loss function (MSE): 0.24217607295406823331\n",
            "Época 2100, Loss function (MSE): 0.24039845122303099556\n",
            "Época 2200, Loss function (MSE): 0.23821589949388147223\n",
            "Época 2300, Loss function (MSE): 0.23555166159545665172\n",
            "Época 2400, Loss function (MSE): 0.23232832591302993164\n",
            "Época 2500, Loss function (MSE): 0.22848138808720558357\n",
            "Época 2600, Loss function (MSE): 0.22397980821538399088\n",
            "Época 2700, Loss function (MSE): 0.21884784819933550404\n",
            "Época 2800, Loss function (MSE): 0.21317595404126379877\n",
            "Época 2900, Loss function (MSE): 0.20710882888152229442\n",
            "Época 3000, Loss function (MSE): 0.20081073357735340634\n",
            "Época 3100, Loss function (MSE): 0.19442285113040913558\n",
            "Época 3200, Loss function (MSE): 0.18803101199884933448\n",
            "Época 3300, Loss function (MSE): 0.18165268812468515769\n",
            "Época 3400, Loss function (MSE): 0.17524109804130935664\n",
            "Época 3500, Loss function (MSE): 0.16870006088768418895\n",
            "Época 3600, Loss function (MSE): 0.16190535975460429441\n",
            "Época 3700, Loss function (MSE): 0.15473191994066992638\n",
            "Época 3800, Loss function (MSE): 0.14708664072737837047\n",
            "Época 3900, Loss function (MSE): 0.13894225008454641479\n",
            "Época 4000, Loss function (MSE): 0.13036064616577747177\n",
            "Época 4100, Loss function (MSE): 0.12149256778759875974\n",
            "Época 4200, Loss function (MSE): 0.11254987676656674767\n",
            "Época 4300, Loss function (MSE): 0.10376150277692072765\n",
            "Época 4400, Loss function (MSE): 0.09533141827922973766\n",
            "Época 4500, Loss function (MSE): 0.08741209246298255187\n",
            "Época 4600, Loss function (MSE): 0.08009642817984408136\n",
            "Época 4700, Loss function (MSE): 0.07342348507499102395\n",
            "Época 4800, Loss function (MSE): 0.06739100408623668881\n",
            "Época 4900, Loss function (MSE): 0.06196911697384557827\n",
            "Época 5000, Loss function (MSE): 0.05711209978302374257\n",
            "Época 5100, Loss function (MSE): 0.05276708540411528814\n",
            "Época 5200, Loss function (MSE): 0.04887985235687165864\n",
            "Época 5300, Loss function (MSE): 0.04539829864175377178\n",
            "Época 5400, Loss function (MSE): 0.04227428311060659610\n",
            "Época 5500, Loss function (MSE): 0.03946440851629774010\n",
            "Época 5600, Loss function (MSE): 0.03693016711219392761\n",
            "Época 5700, Loss function (MSE): 0.03463773208012388416\n",
            "Época 5800, Loss function (MSE): 0.03255757398613697007\n",
            "Época 5900, Loss function (MSE): 0.03066400974151268707\n",
            "Época 6000, Loss function (MSE): 0.02893474500690390930\n",
            "Época 6100, Loss function (MSE): 0.02735044208658427706\n",
            "Época 6200, Loss function (MSE): 0.02589432809267937577\n",
            "Época 6300, Loss function (MSE): 0.02455184823654144033\n",
            "Época 6400, Loss function (MSE): 0.02331036368039712467\n",
            "Época 6500, Loss function (MSE): 0.02215889064191108732\n",
            "Época 6600, Loss function (MSE): 0.02108787626262341799\n",
            "Época 6700, Loss function (MSE): 0.02008900644700076232\n",
            "Época 6800, Loss function (MSE): 0.01915504104747931674\n",
            "Época 6900, Loss function (MSE): 0.01827967217678401479\n",
            "Época 7000, Loss function (MSE): 0.01745740193749439201\n",
            "Época 7100, Loss function (MSE): 0.01668343639495877689\n",
            "Época 7200, Loss function (MSE): 0.01595359314146203508\n",
            "Época 7300, Loss function (MSE): 0.01526422028375003237\n",
            "Época 7400, Loss function (MSE): 0.01461212511921817017\n",
            "Época 7500, Loss function (MSE): 0.01399451114040086742\n",
            "Época 7600, Loss function (MSE): 0.01340892231856043865\n",
            "Época 7700, Loss function (MSE): 0.01285319386397807892\n",
            "Época 7800, Loss function (MSE): 0.01232540884494868344\n",
            "Época 7900, Loss function (MSE): 0.01182386017464073270\n",
            "Época 8000, Loss function (MSE): 0.01134701755298430509\n",
            "Época 8100, Loss function (MSE): 0.01089349898985553754\n",
            "Época 8200, Loss function (MSE): 0.01046204654738564464\n",
            "Época 8300, Loss function (MSE): 0.01005150593443231849\n",
            "Época 8400, Loss function (MSE): 0.00966080957501669682\n",
            "Época 8500, Loss function (MSE): 0.00928896276264774313\n",
            "Época 8600, Loss function (MSE): 0.00893503250919415806\n",
            "Época 8700, Loss function (MSE): 0.00859813870309399791\n",
            "Época 8800, Loss function (MSE): 0.00827744720780896476\n",
            "Época 8900, Loss function (MSE): 0.00797216455651698387\n",
            "Época 9000, Loss function (MSE): 0.00768153393106420571\n",
            "Época 9100, Loss function (MSE): 0.00740483214967883017\n",
            "Época 9200, Loss function (MSE): 0.00714136742639728730\n",
            "Época 9300, Loss function (MSE): 0.00689047770337471166\n",
            "Época 9400, Loss function (MSE): 0.00665152939351281499\n",
            "Época 9500, Loss function (MSE): 0.00642391640392891462\n",
            "Época 9600, Loss function (MSE): 0.00620705933997705607\n",
            "Época 9700, Loss function (MSE): 0.00600040481451722361\n",
            "Época 9800, Loss function (MSE): 0.00580342480791690672\n",
            "Época 9900, Loss function (MSE): 0.00561561604111575612\n",
            "Época 10000, Loss function (MSE): 0.00543649933736751589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predicciones\n",
        "input_layer = X #asigna la matriz de entradas X (por ejemplo, los datos de entrenamiento o prueba) a la variable input_layer\n",
        "hidden_layer_input = np.dot(input_layer, weights_input_hidden) + bias_hidden #calcula lo que entra a cada neurona de la capa oculta\n",
        "hidden_layer_output = sigmoid(hidden_layer_input) #aplica la función de activación sigmoide a cada valor del paso anterior\n",
        "output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output #calcula la entrada de la capa de salida (antes de activarla)\n",
        "predictions = sigmoid(output_layer_input) #aplica nuevamente la función sigmoide, pero ahora para obtener la salida final del modelo\n",
        "\n",
        "#muestra, para cada muestra del conjunto de datos:\n",
        "print(\"Resultados finales:\")\n",
        "for i in range(0, len(X)):\n",
        "    print(f\"Input: {X[i]}, Target: {y[i]}, Predictions {predictions[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGq0Wxu6XWr0",
        "outputId": "913815cd-a41c-48ab-9345-7e3f2f45b488"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados finales:\n",
            "Input: [0 0], Target: [0], Predictions [0.05951142]\n",
            "Input: [0 1], Target: [1], Predictions [0.93777756]\n",
            "Input: [1 0], Target: [1], Predictions [0.91735137]\n",
            "Input: [1 1], Target: [0], Predictions [0.08657346]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#muestra el Error Cuadrático Medio (MSE), una de las métricas más comunes para evaluar redes neuronales\n",
        "print(f\"Error Cuadrático Medio (MSE): {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dfohDlvXhta",
        "outputId": "13a968e3-5578-4e21-aefc-88220380e988"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error Cuadrático Medio (MSE): 0.005434750503975613\n"
          ]
        }
      ]
    }
  ]
}