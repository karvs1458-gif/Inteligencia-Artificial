{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYF8vkrtAoVAn0J7pr07rb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karvs1458-gif/Inteligencia-Artificial/blob/main/Not.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDnyhL2j0Mht",
        "outputId": "e1debf2d-1949-4620-a94d-3020f5f8add4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Optimized Weights are [0.99], and bias is 0.99\n",
            "Epoch 2, Optimized Weights are [0.98], and bias is 0.98\n",
            "Epoch 3, Optimized Weights are [0.97], and bias is 0.97\n",
            "Epoch 4, Optimized Weights are [0.96], and bias is 0.96\n",
            "Epoch 5, Optimized Weights are [0.95], and bias is 0.95\n",
            "Epoch 6, Optimized Weights are [0.94], and bias is 0.94\n",
            "Epoch 7, Optimized Weights are [0.93], and bias is 0.9299999999999999\n",
            "Epoch 8, Optimized Weights are [0.92], and bias is 0.9199999999999999\n",
            "Epoch 9, Optimized Weights are [0.91], and bias is 0.9099999999999999\n",
            "Epoch 10, Optimized Weights are [0.9], and bias is 0.8999999999999999\n",
            "Epoch 11, Optimized Weights are [0.89], and bias is 0.8899999999999999\n",
            "Epoch 12, Optimized Weights are [0.88], and bias is 0.8799999999999999\n",
            "Epoch 13, Optimized Weights are [0.87], and bias is 0.8699999999999999\n",
            "Epoch 14, Optimized Weights are [0.86], and bias is 0.8599999999999999\n",
            "Epoch 15, Optimized Weights are [0.85], and bias is 0.8499999999999999\n",
            "Epoch 16, Optimized Weights are [0.84], and bias is 0.8399999999999999\n",
            "Epoch 17, Optimized Weights are [0.83], and bias is 0.8299999999999998\n",
            "Epoch 18, Optimized Weights are [0.82], and bias is 0.8199999999999998\n",
            "Epoch 19, Optimized Weights are [0.81], and bias is 0.8099999999999998\n",
            "Epoch 20, Optimized Weights are [0.8], and bias is 0.7999999999999998\n",
            "Epoch 21, Optimized Weights are [0.79], and bias is 0.7899999999999998\n",
            "Epoch 22, Optimized Weights are [0.78], and bias is 0.7799999999999998\n",
            "Epoch 23, Optimized Weights are [0.77], and bias is 0.7699999999999998\n",
            "Epoch 24, Optimized Weights are [0.76], and bias is 0.7599999999999998\n",
            "Epoch 25, Optimized Weights are [0.75], and bias is 0.7499999999999998\n",
            "Epoch 26, Optimized Weights are [0.74], and bias is 0.7399999999999998\n",
            "Epoch 27, Optimized Weights are [0.73], and bias is 0.7299999999999998\n",
            "Epoch 28, Optimized Weights are [0.72], and bias is 0.7199999999999998\n",
            "Epoch 29, Optimized Weights are [0.71], and bias is 0.7099999999999997\n",
            "Epoch 30, Optimized Weights are [0.7], and bias is 0.6999999999999997\n",
            "Epoch 31, Optimized Weights are [0.69], and bias is 0.6899999999999997\n",
            "Epoch 32, Optimized Weights are [0.68], and bias is 0.6799999999999997\n",
            "Epoch 33, Optimized Weights are [0.67], and bias is 0.6699999999999997\n",
            "Epoch 34, Optimized Weights are [0.66], and bias is 0.6599999999999997\n",
            "Epoch 35, Optimized Weights are [0.65], and bias is 0.6499999999999997\n",
            "Epoch 36, Optimized Weights are [0.64], and bias is 0.6399999999999997\n",
            "Epoch 37, Optimized Weights are [0.63], and bias is 0.6299999999999997\n",
            "Epoch 38, Optimized Weights are [0.62], and bias is 0.6199999999999997\n",
            "Epoch 39, Optimized Weights are [0.61], and bias is 0.6099999999999997\n",
            "Epoch 40, Optimized Weights are [0.6], and bias is 0.5999999999999996\n",
            "Epoch 41, Optimized Weights are [0.59], and bias is 0.5899999999999996\n",
            "Epoch 42, Optimized Weights are [0.58], and bias is 0.5799999999999996\n",
            "Epoch 43, Optimized Weights are [0.57], and bias is 0.5699999999999996\n",
            "Epoch 44, Optimized Weights are [0.56], and bias is 0.5599999999999996\n",
            "Epoch 45, Optimized Weights are [0.55], and bias is 0.5499999999999996\n",
            "Epoch 46, Optimized Weights are [0.54], and bias is 0.5399999999999996\n",
            "Epoch 47, Optimized Weights are [0.53], and bias is 0.5299999999999996\n",
            "Epoch 48, Optimized Weights are [0.52], and bias is 0.5199999999999996\n",
            "Epoch 49, Optimized Weights are [0.51], and bias is 0.5099999999999996\n",
            "Epoch 50, Optimized Weights are [0.5], and bias is 0.49999999999999956\n",
            "Epoch 51, Optimized Weights are [0.49], and bias is 0.48999999999999955\n",
            "Epoch 52, Optimized Weights are [0.48], and bias is 0.47999999999999954\n",
            "Epoch 53, Optimized Weights are [0.47], and bias is 0.46999999999999953\n",
            "Epoch 54, Optimized Weights are [0.46], and bias is 0.4599999999999995\n",
            "Epoch 55, Optimized Weights are [0.45], and bias is 0.4499999999999995\n",
            "Epoch 56, Optimized Weights are [0.44], and bias is 0.4399999999999995\n",
            "Epoch 57, Optimized Weights are [0.43], and bias is 0.4299999999999995\n",
            "Epoch 58, Optimized Weights are [0.42], and bias is 0.4199999999999995\n",
            "Epoch 59, Optimized Weights are [0.41], and bias is 0.4099999999999995\n",
            "Epoch 60, Optimized Weights are [0.4], and bias is 0.39999999999999947\n",
            "Epoch 61, Optimized Weights are [0.39], and bias is 0.38999999999999946\n",
            "Epoch 62, Optimized Weights are [0.38], and bias is 0.37999999999999945\n",
            "Epoch 63, Optimized Weights are [0.37], and bias is 0.36999999999999944\n",
            "Epoch 64, Optimized Weights are [0.36], and bias is 0.35999999999999943\n",
            "Epoch 65, Optimized Weights are [0.35], and bias is 0.3499999999999994\n",
            "Epoch 66, Optimized Weights are [0.34], and bias is 0.3399999999999994\n",
            "Epoch 67, Optimized Weights are [0.33], and bias is 0.3299999999999994\n",
            "Epoch 68, Optimized Weights are [0.32], and bias is 0.3199999999999994\n",
            "Epoch 69, Optimized Weights are [0.31], and bias is 0.3099999999999994\n",
            "Epoch 70, Optimized Weights are [0.3], and bias is 0.2999999999999994\n",
            "Epoch 71, Optimized Weights are [0.29], and bias is 0.28999999999999937\n",
            "Epoch 72, Optimized Weights are [0.28], and bias is 0.27999999999999936\n",
            "Epoch 73, Optimized Weights are [0.27], and bias is 0.26999999999999935\n",
            "Epoch 74, Optimized Weights are [0.26], and bias is 0.25999999999999934\n",
            "Epoch 75, Optimized Weights are [0.25], and bias is 0.24999999999999933\n",
            "Epoch 76, Optimized Weights are [0.24], and bias is 0.23999999999999932\n",
            "Epoch 77, Optimized Weights are [0.23], and bias is 0.22999999999999932\n",
            "Epoch 78, Optimized Weights are [0.22], and bias is 0.2199999999999993\n",
            "Epoch 79, Optimized Weights are [0.21], and bias is 0.2099999999999993\n",
            "Epoch 80, Optimized Weights are [0.2], and bias is 0.1999999999999993\n",
            "Epoch 81, Optimized Weights are [0.19], and bias is 0.18999999999999928\n",
            "Epoch 82, Optimized Weights are [0.18], and bias is 0.17999999999999927\n",
            "Epoch 83, Optimized Weights are [0.17], and bias is 0.16999999999999926\n",
            "Epoch 84, Optimized Weights are [0.16], and bias is 0.15999999999999925\n",
            "Epoch 85, Optimized Weights are [0.15], and bias is 0.14999999999999925\n",
            "Epoch 86, Optimized Weights are [0.14], and bias is 0.13999999999999924\n",
            "Epoch 87, Optimized Weights are [0.13], and bias is 0.12999999999999923\n",
            "Epoch 88, Optimized Weights are [0.12], and bias is 0.11999999999999923\n",
            "Epoch 89, Optimized Weights are [0.11], and bias is 0.10999999999999924\n",
            "Epoch 90, Optimized Weights are [0.1], and bias is 0.09999999999999924\n",
            "Epoch 91, Optimized Weights are [0.09], and bias is 0.08999999999999925\n",
            "Epoch 92, Optimized Weights are [0.08], and bias is 0.07999999999999925\n",
            "Epoch 93, Optimized Weights are [0.07], and bias is 0.06999999999999926\n",
            "Epoch 94, Optimized Weights are [0.06], and bias is 0.059999999999999255\n",
            "Epoch 95, Optimized Weights are [0.05], and bias is 0.04999999999999925\n",
            "Epoch 96, Optimized Weights are [0.04], and bias is 0.03999999999999925\n",
            "Epoch 97, Optimized Weights are [0.03], and bias is 0.02999999999999925\n",
            "Epoch 98, Optimized Weights are [0.02], and bias is 0.019999999999999248\n",
            "Epoch 99, Optimized Weights are [0.01], and bias is 0.009999999999999247\n",
            "Epoch 100, Optimized Weights are [-7.52869989e-16], and bias is -7.528699885739343e-16\n",
            "Epoch 101, Optimized Weights are [-0.01], and bias is -7.528699885739343e-16\n",
            "Epoch 102, Optimized Weights are [-0.01], and bias is 0.009999999999999247\n",
            "Optimized Weights are [-0.01] and bias is 0.009999999999999247\n",
            "Input: [0], Predictions: 1\n",
            "Input: [1], Predictions: 0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# Entradas para el perceptron\n",
        "X = np.array([\n",
        "    [0],\n",
        "    [1]\n",
        "])\n",
        "# Salidas\n",
        "Y = np.array([1,0])\n",
        "# Pesos para las entradas\n",
        "weights = np.array([1.0])\n",
        "# Tasa de aprendizaje\n",
        "lr = 0.01\n",
        "# Epocas\n",
        "epochs = 102\n",
        "# Sesgo\n",
        "bias =  1.0\n",
        "class Perceptron:\n",
        "    def __init__(self, lr, epochs, weights, bias):\n",
        "        \"\"\"\n",
        "            Constructor del perceptron:\n",
        "            Guarda las variables\n",
        "            lr -> tasa de aprendizaje\n",
        "            epochs -> numero de epocas\n",
        "            weights -> vector de pesos iniciales\n",
        "            bias -> sesgo inicial\n",
        "        \"\"\"\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.weights = weights\n",
        "        self.bias = bias\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        \"\"\"\n",
        "            Realiza el entrenamiento del Perceptron.\n",
        "        \"\"\"\n",
        "        # Recorre el dataset la cantidad indicada en epocas\n",
        "        for epoch in range(self.epochs):\n",
        "            for j in range(X.shape[0]):\n",
        "                # Calcula la salida del perceptrón para la entrada actual\n",
        "                y_pred = self.activation_function(np.dot(self.weights, X[j]) + self.bias)\n",
        "                # Calcula el error\n",
        "                loss = Y[j] - y_pred\n",
        "                # Actualiza los pesos y el sesgo\n",
        "                self.weights += self.lr * loss * X[j]\n",
        "                self.bias += self.lr * loss\n",
        "            print(f\"Epoch {epoch+1}, Optimized Weights are {self.weights}, and bias is {self.bias}\")\n",
        "        # Imprime los valores finales de los parámetros aprendidos\n",
        "        print(f\"Optimized Weights are {self.weights} and bias is {self.bias}\")\n",
        "\n",
        "    def activation_function(self, activation):\n",
        "        \"\"\"\n",
        "            Función de activacion escalon\n",
        "        \"\"\"\n",
        "        return 1 if activation >= 0 else 0\n",
        "\n",
        "    def prediction(self, X):\n",
        "        \"\"\"\n",
        "            Calcula la salida del Perceptron para cada fila de entradas X.\n",
        "        \"\"\"\n",
        "        # Calcula producto punto + bias para todas las entradas\n",
        "        sum_ = np.dot(X, self.weights) + self.bias\n",
        "        # Mensaje input y su predicción\n",
        "        for i, s in enumerate(sum_):\n",
        "            print(f\"Input: {X[i]}, Predictions: {self.activation_function(sum_[i])}\")\n",
        "        # Devuelve un array con todas las predicciones\n",
        "        return np.array([self.activation_function(s) for s in sum_])\n",
        "        # Crear una instancia del perceptrón\n",
        "p = Perceptron(lr=lr, epochs=epochs, weights=weights, bias=bias)\n",
        "# Entrenar el modelo\n",
        "p.fit(X, Y)\n",
        "# Usar el modelo entrenado para realizar predicciones\n",
        "predictions = p.prediction(X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T6bMOxh23_ds"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}